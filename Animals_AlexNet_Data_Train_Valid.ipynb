{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benschwarz3/Spring-2023/blob/main/Animals_AlexNet_Data_Train_Valid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BLD5aS3Eh5kG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from google.colab import drive\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRUko9SmiAR4",
        "outputId": "2250e356-64f8-4484-c13f-5e88b1f05180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HIvr8fVTiR3n"
      },
      "outputs": [],
      "source": [
        "# 2. Load labeled images from folders\n",
        "# data_dir = '/content/drive/MyDrive/MAP Data 2023/Flowers'\n",
        "data_dir = '/content/drive/MyDrive/MAP Data 2023/Animals'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt-RSupRi5mC",
        "outputId": "fdad0bbb-c3dc-4df2-a440-5d4b27f50fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MAP Data 2023/Animals\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/MAP Data 2023/Animals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umv41WtGjLow",
        "outputId": "7207a62f-9673-4379-e4d8-3aa5a410bd84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mTrain\u001b[0m/  \u001b[01;34mValid\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5uUGwb6QjONm"
      },
      "outputs": [],
      "source": [
        "# 3. Pre-process the data and create data loaders\n",
        "data_transforms = {\n",
        "    'Train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'Valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMJ79F8TjjCv",
        "outputId": "d3e24363-4b72-4fd0-ae48-6fe5de90d663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "image_datasets = {x: datasets.ImageFolder(data_dir + '/' + x, data_transforms[x]) for x in ['Train', 'Valid']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4) for x in ['Train', 'Valid']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['Train', 'Valid']}\n",
        "class_names = image_datasets['Train'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_dUNnT3jlYy",
        "outputId": "214e73df-296b-457a-ed3f-7141869cef50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:02<00:00, 93.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# 4. Set up the AlexNet architecture\n",
        "alexnet = models.alexnet(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5inPHf_GkIMQ",
        "outputId": "1b0967cf-7e61-489a-88fd-6c7c4f5739fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oi6Bn3UYkMc3"
      },
      "outputs": [],
      "source": [
        "num_ftrs = alexnet.classifier[6].in_features\n",
        "alexnet.classifier[6] = nn.Linear(num_ftrs, len(class_names)) # Change last layer\n",
        "alexnet = alexnet.to(device) # Put on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiVy49inkQ2d",
        "outputId": "af076207-1750-4e09-d615-c0b6e5e7cc61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeOn3wggkSsF",
        "outputId": "ea73e1c2-9f9b-4a05-ab4b-da307d647d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 55, 55]          23,296\n",
            "              ReLU-2           [-1, 64, 55, 55]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                    [-1, 2]           8,194\n",
            "================================================================\n",
            "Total params: 57,012,034\n",
            "Trainable params: 57,012,034\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 8.37\n",
            "Params size (MB): 217.48\n",
            "Estimated Total Size (MB): 226.43\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(alexnet, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb9eEOVkkUpc",
        "outputId": "d538ff60-68e6-4ede-b93d-1d65f7bf6ea3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Land Animals', 'Sea Animals']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVJ6i-5QkW4h",
        "outputId": "f48cb66c-ac0d-4cc6-ef5f-b98e8acb0baa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Train': 54, 'Valid': 17}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fpPFUOfzkYkR"
      },
      "outputs": [],
      "source": [
        "for inputs, labels in dataloaders[\"Train\"]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjBy32C-kaWH",
        "outputId": "57537a74-b8eb-439a-8b0d-6053333929dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ssyePPXkfwr",
        "outputId": "eff221fa-6762-4d67-ee2e-a851756682c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaHorgJskha1",
        "outputId": "9f7223da-0628-405d-834c-49238aa9399b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "62nxwwYZki8e"
      },
      "outputs": [],
      "source": [
        "outputs = alexnet(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvgP7rb6kkt2",
        "outputId": "fc220aee-7345-49f0-9328-ec0b209e42bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJOsyEFUkmWr",
        "outputId": "7b613524-e3db-4bc2-f174-0a200f794705"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6463,  0.5468],\n",
              "        [ 0.4874,  1.1338],\n",
              "        [-0.0195,  1.3709],\n",
              "        [-0.8189, -0.6090],\n",
              "        [ 0.6136,  1.7315],\n",
              "        [-0.3662, -0.0517]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGquXbmAkoCw",
        "outputId": "c3349c7a-9917-45ed-bb36-72c806109b7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.6463,  1.1338,  1.3709, -0.6090,  1.7315, -0.0517],\n",
              "       grad_fn=<MaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "torch.max(outputs,1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA2W16yDkp_O",
        "outputId": "526f64d5-1a10-4311-d296-9344b6f0925f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "torch.max(outputs,1)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rC5E0ZrxkrlC"
      },
      "outputs": [],
      "source": [
        "preds = torch.max(outputs, 1)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZUsYyNbks-K",
        "outputId": "ad53a6f4-2a5c-444a-8e40-fe3ee43cce08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V_CINbukuZL",
        "outputId": "18ccea10-c957-4048-98d1-924839061e7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx8ZnniUkwWs",
        "outputId": "6d0a6f1f-9046-4237-baf5-7967ce9e2ac1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True, False, False, False,  True, False])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "preds == labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMVh8lvfkxw1",
        "outputId": "c6722fda-5599-4a6c-998f-53fc6deb56ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "labels.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jHKNavckzLj",
        "outputId": "0fba9b0f-0ae0-4b3b-bec6-49792c91dff9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3333)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "torch.sum(preds == labels)/labels.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcTijSngk0rW",
        "outputId": "bf3610af-ab33-4358-e8d9-081521c511c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  of  19\n",
            "----------\n",
            "Train Acc: 0.4630\n",
            "Valid Acc: 0.5882\n",
            "1  of  19\n",
            "----------\n",
            "Train Acc: 0.8889\n",
            "Valid Acc: 0.8235\n",
            "2  of  19\n",
            "----------\n",
            "Train Acc: 0.8889\n",
            "Valid Acc: 0.8235\n",
            "3  of  19\n",
            "----------\n",
            "Train Acc: 0.9444\n",
            "Valid Acc: 0.8824\n",
            "4  of  19\n",
            "----------\n",
            "Train Acc: 1.0000\n",
            "Valid Acc: 0.8824\n",
            "5  of  19\n",
            "----------\n",
            "Train Acc: 1.0000\n",
            "Valid Acc: 0.8824\n",
            "6  of  19\n",
            "----------\n",
            "Train Acc: 0.9815\n",
            "Valid Acc: 0.8824\n",
            "7  of  19\n",
            "----------\n",
            "Train Acc: 0.9815\n",
            "Valid Acc: 0.9412\n",
            "8  of  19\n",
            "----------\n",
            "Train Acc: 1.0000\n",
            "Valid Acc: 0.9412\n",
            "9  of  19\n",
            "----------\n",
            "Train Acc: 1.0000\n",
            "Valid Acc: 0.9412\n",
            "10  of  19\n",
            "----------\n",
            "Train Acc: 1.0000\n",
            "Valid Acc: 0.9412\n",
            "11  of  19\n",
            "----------\n",
            "Train Acc: 1.0000\n",
            "Valid Acc: 0.9412\n",
            "12  of  19\n",
            "----------\n",
            "Train Acc: 1.0000\n",
            "Valid Acc: 0.9412\n",
            "13  of  19\n",
            "----------\n",
            "Train Acc: 0.9815\n",
            "Valid Acc: 0.9412\n",
            "14  of  19\n",
            "----------\n",
            "Train Acc: 1.0000\n",
            "Valid Acc: 0.9412\n",
            "15  of  19\n",
            "----------\n",
            "Train Acc: 0.9815\n",
            "Valid Acc: 0.9412\n",
            "16  of  19\n",
            "----------\n",
            "Train Acc: 1.0000\n",
            "Valid Acc: 0.9412\n",
            "17  of  19\n",
            "----------\n",
            "Train Acc: 0.9630\n",
            "Valid Acc: 0.9412\n",
            "18  of  19\n",
            "----------\n",
            "Train Acc: 0.9815\n",
            "Valid Acc: 0.8824\n",
            "19  of  19\n",
            "----------\n",
            "Train Acc: 0.9815\n",
            "Valid Acc: 0.8824\n",
            "Training complete\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(alexnet.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the AlexNet model\n",
        "alexnet.train()\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(epoch, \" of \", num_epochs - 1)\n",
        "    print('-' * 10)\n",
        "\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in dataloaders[\"Train\"]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        \n",
        "\n",
        "        outputs = alexnet(inputs)\n",
        "        preds = torch.max(outputs, 1)[1]\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    print('Train Acc: {:.4f}'.format(running_corrects / dataset_sizes[\"Train\"]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Evaluate the AlexNet model on Validation Data\n",
        "    alexnet.eval()\n",
        "\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in dataloaders[\"Valid\"]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = alexnet(inputs)\n",
        "        preds = torch.max(outputs, 1)[1]\n",
        "\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    acc_valid = running_corrects / dataset_sizes[\"Valid\"]\n",
        "    print('Valid Acc: {:.4f}'.format(acc_valid))\n",
        "    if acc_valid > 0.99:\n",
        "        print(\"Done!\")\n",
        "        break\n",
        "\n",
        "\n",
        "print('Training complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OZg-rCj5lImW",
        "outputId": "cb370b22-6419-4cec-9163-9b38da18b087"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/MAP Data 2023/Animals'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "NWVjMgSJlZ9K"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/drive/MyDrive/MAP Data 2023/Animals/alexnet_classification_animals.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "YoMwLodVluQD"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "torch.save(alexnet.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwM3DscelwYm",
        "outputId": "16c71bbc-babe-48cb-dbbe-68a6bb31d46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alexnet_classification_animals.pth  \u001b[0m\u001b[01;34mTrain\u001b[0m/  \u001b[01;34mValid\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "PWC7MAIZlyvV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "AS5vmVYll3kO"
      },
      "outputs": [],
      "source": [
        "# 1. Load the trained AlexNet model\n",
        "def load_model(model_path):\n",
        "    model = models.alexnet()\n",
        "    num_ftrs = model.classifier[6].in_features\n",
        "    model.classifier[6] = nn.Linear(num_ftrs, len(class_names))\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "g3yl6UOtl8Lu"
      },
      "outputs": [],
      "source": [
        "# 2. Define a function to load an image from a URL and preprocess it\n",
        "def preprocess_image(url, transform):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "    img_tensor = transform(img)\n",
        "    return img_tensor.unsqueeze(0).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "iB4IZQqql-QU"
      },
      "outputs": [],
      "source": [
        "# 3. Perform inference using the loaded model\n",
        "def predict_image_url(url, model):\n",
        "    img_tensor = preprocess_image(url, data_transforms['Valid'])\n",
        "    output = model(img_tensor)\n",
        "    pred = torch.max(output, 1)[1]\n",
        "    return class_names[pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "OA_XnmX2mARB"
      },
      "outputs": [],
      "source": [
        "trained_model = load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "GAXVC-jnmCEt"
      },
      "outputs": [],
      "source": [
        "image_url = 'https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL2hpcHBvLXN1bnNjcmVlbi5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjgyOH19fQ=='"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "qjVs3fLJm1vh"
      },
      "outputs": [],
      "source": [
        "prediction = predict_image_url(image_url, trained_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iLcPZqOm3iK",
        "outputId": "3ef98256-2a42-4752-8711-c1a4a73c65bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class for the input image is: Land Animals\n"
          ]
        }
      ],
      "source": [
        "print(\"The predicted class for the input image is:\", prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOXa2uJeoU4d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kNosukMIqsUZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJttl2YRsniHbN8Zh/i6WQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}